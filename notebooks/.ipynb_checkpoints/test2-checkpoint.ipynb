{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9d7a0b-91f8-43cd-810f-6c27d469a7f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Optional: YAML energy parsing (PyYAML)\n",
    "try:\n",
    "    import yaml  # type: ignore\n",
    "except Exception:\n",
    "    yaml = None\n",
    "    warnings.warn(\"PyYAML not available — YAML-based energy attribution will be skipped.\")\n",
    "\n",
    "# -----------------------------\n",
    "# Absolute paths (edit if needed)\n",
    "# -----------------------------\n",
    "RUN_IDS = {\n",
    "    \"Baseline (JanS, 2MB, 16 Way)\": \"sniper_roi1000_fixedcap2m_20250927T171235Z\",\n",
    "    \"JanS, 2MB, 8 Way\": \"sniper_assoc_jans2mb_8way_20250929T024544Z\",\n",
    "    \"JanS, 16MB, 16 Way\": \"sniper_cap_equal_16mb_20250929T024544Z\",\n",
    "    \"JanS, 32MB, 16 Way\": \"sniper_cap_equal_32mb_20250929T024544Z\",\n",
    "    \"ChungS, 2MB, 16 Way\": \"sniper_dev_chungs_2mb_20250929T024350Z\",\n",
    "    \"UmekiS, 2MB, 16 Way\": \"sniper_dev_umekis_2mb_20250929T024536Z\",\n",
    "    \"XueS, 2MB, 16 Way\": \"sniper_dev_xues_2mb_20250929T024537Z\",\n",
    "}\n",
    "SNIPER_RESULTS_DIR = \\\n",
    "    f\"/home/skataoka26/COSC_498/miniMXE/results/{RUN_IDS['Baseline (JanS, 2MB, 16 Way)']}\"\n",
    "# override to the latest explicit run dir if desired\n",
    "SNIPER_RESULTS_DIR = \\\n",
    "    \"/home/skataoka26/COSC_498/miniMXE/results/sniper_llc_2mb_16w_20251002T020032Z\"\n",
    "DYNAMORIO_LOGS_DIR = \\\n",
    "    \"/home/skataoka26/COSC_498/miniMXE/results_trace/logs\"\n",
    "TIMESTAMP_PREFIX = \"20250929T203551Z\"  # prefix used in DynamoRIO filenames\n",
    "\n",
    "# Path to the YAML used to launch Sniper (for pJ numbers)\n",
    "YAML_CONFIG_PATH = \\\n",
    "    \"/home/skataoka26/COSC_498/miniMXE/config/sniper_2mb_16w_nvsim.yaml\"\n",
    "\n",
    "# -----------------------------\n",
    "# Utilities\n",
    "# -----------------------------\n",
    "def safe_div(numer, denom):\n",
    "    numer = np.array(numer, dtype=float)\n",
    "    denom = np.array(denom, dtype=float)\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        out = np.where((denom > 0) & np.isfinite(denom), numer / denom, np.nan)\n",
    "    return out\n",
    "\n",
    "def geomean(values):\n",
    "    vals = np.array([v for v in np.ravel(values) if v > 0 and np.isfinite(v)], dtype=float)\n",
    "    return float(np.exp(np.mean(np.log(vals)))) if len(vals) else np.nan\n",
    "\n",
    "# --- statistics helpers ---\n",
    "def bootstrap_spearman_ci(x, y, n_boot=10000, alpha=0.05, random_state=0):\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    mask = np.isfinite(x) & np.isfinite(y)\n",
    "    x0 = np.array(x)[mask]\n",
    "    y0 = np.array(y)[mask]\n",
    "    n = len(x0)\n",
    "    if n < 3:\n",
    "        return (np.nan, np.nan, np.nan, n)\n",
    "    obs = pd.Series(x0).corr(pd.Series(y0), method=\"spearman\")\n",
    "    boots = []\n",
    "    for _ in range(n_boot):\n",
    "        idx = rng.integers(0, n, n)\n",
    "        xi = x0[idx]\n",
    "        yi = y0[idx]\n",
    "        try:\n",
    "            r = pd.Series(xi).corr(pd.Series(yi), method=\"spearman\")\n",
    "        except Exception:\n",
    "            r = np.nan\n",
    "        boots.append(r)\n",
    "    boots = np.array([b for b in boots if np.isfinite(b)])\n",
    "    if boots.size == 0:\n",
    "        return (obs, np.nan, np.nan, n)\n",
    "    lo = np.percentile(boots, 100 * alpha / 2.0)\n",
    "    hi = np.percentile(boots, 100 * (1 - alpha/2.0))\n",
    "    return (obs, lo, hi, n)\n",
    "\n",
    "# -----------------------------\n",
    "# Parsing helpers\n",
    "# -----------------------------\n",
    "def parse_sniper(base_dir):\n",
    "    \"\"\"\n",
    "    Walk output_* folders, read summary.csv and energy_bounds.csv,\n",
    "    merge them on (benchmark, config). Return a tidy DataFrame.\n",
    "    We keep LLC event counters (accesses, hits, misses, reads, writes, evicts) when present.\n",
    "    \"\"\"\n",
    "    energy_rows = []\n",
    "    summary_rows = []\n",
    "    print(f\"--- Parsing Sniper results from: {base_dir} ---\")\n",
    "    for root, _, files in os.walk(base_dir):\n",
    "        if os.path.basename(root).startswith(\"output_\") and \"summary.csv\" in files and \"energy_bounds.csv\" in files:\n",
    "            energy_path = os.path.join(root, \"energy_bounds.csv\")\n",
    "            summary_path = os.path.join(root, \"summary.csv\")\n",
    "\n",
    "            e = pd.read_csv(energy_path)\n",
    "            s = pd.read_csv(summary_path)\n",
    "\n",
    "            # Keep columns we use from energy\n",
    "            e_keep = [\n",
    "                \"benchmark\", \"config\", \"time_s\",\n",
    "                \"energy_exact_J\", \"leak_J\", \"dyn_exact_nJ\"\n",
    "            ]\n",
    "            e = e[[c for c in e_keep if c in e.columns]].copy()\n",
    "\n",
    "            # Base columns we want from summary\n",
    "            s_base = [\"benchmark\", \"config\", \"ipc\", \"time_ns\", \"l3_miss_rate_pct\"]\n",
    "            keep_s = [c for c in s_base if c in s.columns]\n",
    "\n",
    "            # Keep any plausible LLC event columns\n",
    "            for col in s.columns:\n",
    "                cl = col.lower()\n",
    "                if (\"l3\" in cl or \"llc\" in cl) and (\n",
    "                    \"access\" in cl or \"read\" in cl or \"write\" in cl or \"hit\" in cl or \"miss\" in cl or \"evict\" in cl or \"wb\" in cl or \"writeback\" in cl\n",
    "                ):\n",
    "                    if col not in keep_s:\n",
    "                        keep_s.append(col)\n",
    "\n",
    "            s = s[keep_s].copy()\n",
    "\n",
    "            # Numeric coercion\n",
    "            for col in [\"time_s\", \"energy_exact_J\", \"leak_J\", \"dyn_exact_nJ\"]:\n",
    "                if col in e.columns:\n",
    "                    e[col] = pd.to_numeric(e[col], errors=\"coerce\")\n",
    "\n",
    "            for col in s.columns:\n",
    "                if col not in (\"benchmark\", \"config\"):\n",
    "                    s[col] = pd.to_numeric(s[col], errors=\"coerce\")\n",
    "\n",
    "            # Convert nJ -> J\n",
    "            if \"dyn_exact_nJ\" in e.columns:\n",
    "                e[\"dyn_exact_J\"] = e[\"dyn_exact_nJ\"] * 1e-9\n",
    "\n",
    "            energy_rows.append(e)\n",
    "            summary_rows.append(s)\n",
    "\n",
    "    if not energy_rows or not summary_rows:\n",
    "        raise FileNotFoundError(\n",
    "            \"Could not find summary.csv and energy_bounds.csv in output_* directories under: \" + base_dir\n",
    "        )\n",
    "\n",
    "    E = pd.concat(energy_rows, ignore_index=True)\n",
    "    S = pd.concat(summary_rows, ignore_index=True)\n",
    "\n",
    "    df = pd.merge(E, S, on=[\"benchmark\", \"config\"], how=\"inner\")\n",
    "\n",
    "    # minimal sanity\n",
    "    df = df.dropna(subset=[\"benchmark\", \"config\", \"time_s\", \"energy_exact_J\"])\n",
    "    print(f\"Sniper parse complete. Merged DataFrame shape: {df.shape}\")\n",
    "    print(f\"Sniper columns found: {df.columns.tolist()}\")\n",
    "    print(\"-\" * 20)\n",
    "    return df\n",
    "\n",
    "\n",
    "def _kv_from_line(s: str) -> dict:\n",
    "    \"\"\"Extract numeric key=value pairs from one rwstats line. 'scope' handled separately.\"\"\"\n",
    "    kv = {}\n",
    "    m = re.search(r\"\\bscope=(\\w+)\", s)\n",
    "    if m:\n",
    "        kv[\"scope\"] = m.group(1)\n",
    "\n",
    "    for k, v in re.findall(r\"([A-Za-z0-9_]+)=([+\\-]?(?:\\d+(?:\\.\\d*)?|\\.\\d+)(?:[eE][+\\-]?\\d+)?|nan)\", s):\n",
    "        try:\n",
    "            kv[k] = float(\"nan\") if v.lower() == \"nan\" else float(v)\n",
    "        except Exception:\n",
    "            pass\n",
    "    return kv\n",
    "\n",
    "\n",
    "def parse_dynamorio(logs_dir, ts_prefix):\n",
    "    \"\"\"\n",
    "    Parse DynamoRIO log files. For each file, grab the LAST stats-like line\n",
    "    (lines contain 'scope='). File name format: {ts_prefix}_<benchmark>_instr.rwstats.log\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    print(f\"\\n--- Parsing DynamoRIO logs from: {logs_dir} with prefix '{ts_prefix}' ---\")\n",
    "    if not os.path.isdir(logs_dir):\n",
    "        print(\"DynamoRIO logs directory not found. Returning empty DataFrame.\")\n",
    "        print(\"-\" * 20)\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    found_files = 0\n",
    "    for fname in os.listdir(logs_dir):\n",
    "        if not (fname.startswith(ts_prefix) and fname.endswith(\"_instr.rwstats.log\")):\n",
    "            continue\n",
    "        m = re.match(rf\"{re.escape(ts_prefix)}_(.+?)_instr\\.rwstats\\.log$\", fname)\n",
    "        if not m:\n",
    "            continue\n",
    "\n",
    "        found_files += 1\n",
    "        benchmark = m.group(1)\n",
    "        fpath = os.path.join(logs_dir, fname)\n",
    "\n",
    "        last = None\n",
    "        with open(fpath, \"r\", errors=\"ignore\") as f:\n",
    "            for line in f:\n",
    "                t = line.strip()\n",
    "                if \"scope=\" in t and \"=\" in t:\n",
    "                    last = t\n",
    "\n",
    "        if not last:\n",
    "            continue\n",
    "\n",
    "        kv = _kv_from_line(last)\n",
    "        kv[\"benchmark\"] = benchmark\n",
    "        rows.append(kv)\n",
    "\n",
    "    print(f\"Found and processed {found_files} matching log files.\")\n",
    "    df = pd.DataFrame(rows) if rows else pd.DataFrame()\n",
    "    if not df.empty:\n",
    "        print(f\"DynamoRIO parse complete. DataFrame shape: {df.shape}\")\n",
    "        print(f\"DynamoRIO columns found: {df.columns.tolist()}\")\n",
    "    else:\n",
    "        print(\"DynamoRIO parse complete. No data found, returning empty DataFrame.\")\n",
    "    print(\"-\" * 20)\n",
    "    return df\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# LLC event helpers (NEW: explicit access/hit/miss detection)\n",
    "# -----------------------------\n",
    "def _series_or_none(df, colname):\n",
    "    if colname in df.columns:\n",
    "        s = pd.to_numeric(df[colname], errors=\"coerce\")\n",
    "        return s if s.notna().any() else None\n",
    "    return None\n",
    "\n",
    "\n",
    "def _choose_col(df_config, must_terms, maybes=(\"l3\", \"llc\")):\n",
    "    \"\"\"Best-populated column whose lowercase name contains all must_terms and any maybes.\"\"\"\n",
    "    best = None\n",
    "    best_pop = -1\n",
    "    for c in df_config.columns:\n",
    "        cl = c.lower()\n",
    "        if all(t in cl for t in must_terms) and any(m in cl for m in maybes):\n",
    "            ser = pd.to_numeric(df_config[c], errors=\"coerce\")\n",
    "            pop = ser.notna().sum()\n",
    "            if pop > best_pop:\n",
    "                best, best_pop = c, pop\n",
    "    return best\n",
    "\n",
    "\n",
    "def detect_total_accesses(df_config):\n",
    "    \"\"\"\n",
    "    Prefer a direct total-access column:\n",
    "      1) l3_accesses_db / llc_accesses_db (or ROI variants)\n",
    "      2) l3_accesses / llc_accesses\n",
    "      3) Fallback: read_hits + write_hits + l3_misses_db (or misses)\n",
    "    Returns Series or None.\n",
    "    \"\"\"\n",
    "    if df_config is None or df_config.empty:\n",
    "        return None\n",
    "\n",
    "    prefer_exact = [\n",
    "        \"l3_accesses_db\", \"llc_accesses_db\",\n",
    "        \"roi_l3_accesses_db\", \"roi_llc_accesses_db\",\n",
    "        \"roi_l3_accesses\", \"roi_llc_accesses\",\n",
    "        \"l3_accesses\", \"llc_accesses\",\n",
    "    ]\n",
    "    for name in prefer_exact:\n",
    "        s = _series_or_none(df_config, name)\n",
    "        if s is not None:\n",
    "            print(f\"[Accesses] Using direct column for total accesses: '{name}'\")\n",
    "            return s\n",
    "\n",
    "    # Fallback: hits + misses\n",
    "    rh = _choose_col(df_config, (\"read\", \"hit\"))\n",
    "    wh = _choose_col(df_config, (\"write\", \"hit\"))\n",
    "    ms = (\n",
    "        _series_or_none(df_config, \"l3_misses_db\")\n",
    "        or _series_or_none(df_config, \"llc_misses_db\")\n",
    "        or (_series_or_none(df_config, _choose_col(df_config, (\"miss\",))) if _choose_col(df_config, (\"miss\",)) else None)\n",
    "    )\n",
    "\n",
    "    parts = []\n",
    "    labels = []\n",
    "    if rh:\n",
    "        parts.append(pd.to_numeric(df_config[rh], errors=\"coerce\"))\n",
    "        labels.append(rh)\n",
    "    if wh:\n",
    "        parts.append(pd.to_numeric(df_config[wh], errors=\"coerce\"))\n",
    "        labels.append(wh)\n",
    "    if ms is not None:\n",
    "        parts.append(ms)\n",
    "        labels.append(ms.name if hasattr(ms, \"name\") and ms.name else \"misses\")\n",
    "\n",
    "    if parts:\n",
    "        total = sum(parts)\n",
    "        if total.notna().any():\n",
    "            print(\"[Accesses] No direct total; falling back to: \" + \" + \".join(labels))\n",
    "            return total\n",
    "\n",
    "    print(\"[Accesses] No suitable total-access columns found.\")\n",
    "    return None\n",
    "\n",
    "\n",
    "def detect_total_hits(df_config):\n",
    "    \"\"\"Total hits = read_hits + write_hits (Series or None).\"\"\"\n",
    "    if df_config is None or df_config.empty:\n",
    "        return None\n",
    "    rh = _choose_col(df_config, (\"read\", \"hit\"))\n",
    "    wh = _choose_col(df_config, (\"write\", \"hit\"))\n",
    "    parts = []\n",
    "    labels = []\n",
    "    if rh:\n",
    "        parts.append(pd.to_numeric(df_config[rh], errors=\"coerce\"))\n",
    "        labels.append(rh)\n",
    "    if wh:\n",
    "        parts.append(pd.to_numeric(df_config[wh], errors=\"coerce\"))\n",
    "        labels.append(wh)\n",
    "    if parts:\n",
    "        total = sum(parts)\n",
    "        if total.notna().any():\n",
    "            print(\"[Hits] Using: \" + \" + \".join(labels))\n",
    "            return total\n",
    "    print(\"[Hits] No suitable hit columns found.\")\n",
    "    return None\n",
    "\n",
    "\n",
    "def detect_misses(df_config):\n",
    "    \"\"\"Return a Series for LLC/L3 misses (prefer *_misses_db).\"\"\"\n",
    "    if df_config is None or df_config.empty:\n",
    "        return None\n",
    "    for name in [\"l3_misses_db\", \"llc_misses_db\", \"roi_l3_misses\", \"roi_llc_misses\", \"l3_misses\", \"llc_misses\"]:\n",
    "        s = _series_or_none(df_config, name)\n",
    "        if s is not None:\n",
    "            print(f\"[Misses] Using column: '{name}'\")\n",
    "            return s\n",
    "    # As a last resort: approximate via miss-rate * accesses if both exist\n",
    "    acc = detect_total_accesses(df_config)\n",
    "    if acc is not None and \"l3_miss_rate_pct\" in df_config.columns:\n",
    "        misses = pd.to_numeric(df_config[\"l3_miss_rate_pct\"], errors=\"coerce\")/100.0 * pd.to_numeric(acc, errors=\"coerce\")\n",
    "        if misses.notna().any():\n",
    "            print(\"[Misses] Approximated via l3_miss_rate_pct × total_accesses\")\n",
    "            return misses\n",
    "    print(\"[Misses] No miss columns available.\")\n",
    "    return None\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Plot helpers\n",
    "# -----------------------------\n",
    "def grouped_barh(ax, labels, a_values, b_values, a_label, b_label, title, x_label):\n",
    "    y = np.arange(len(labels))\n",
    "    h = 0.38\n",
    "    ax.barh(y - h/2, a_values, height=h, label=a_label)\n",
    "    ax.barh(y + h/2, b_values, height=h, label=b_label)\n",
    "    ax.set_yticks(y)\n",
    "    ax.set_yticklabels(labels)\n",
    "    ax.invert_yaxis()  # top item at top\n",
    "    ax.grid(True, axis=\"x\", linestyle=\":\", linewidth=0.5)\n",
    "    ax.set_title(title, fontsize=11)\n",
    "    ax.set_xlabel(x_label, fontsize=10)\n",
    "    ax.tick_params(axis=\"y\", labelsize=8)\n",
    "    ax.tick_params(axis=\"x\", labelsize=8)\n",
    "    ax.legend(fontsize=8, frameon=False)\n",
    "\n",
    "\n",
    "def corr_heatmap(ax, matrix, row_labels, col_labels, title):\n",
    "    im = ax.imshow(matrix, aspect=\"auto\", vmin=-1, vmax=1, cmap=\"coolwarm\")\n",
    "    ax.set_yticks(np.arange(len(row_labels)))\n",
    "    ax.set_yticklabels(row_labels)\n",
    "    ax.set_xticks(np.arange(len(col_labels)))\n",
    "    ax.set_xticklabels(col_labels, rotation=90)\n",
    "    ax.set_title(title, fontsize=11)\n",
    "    for i in range(matrix.shape[0]):\n",
    "        for j in range(matrix.shape[1]):\n",
    "            val = matrix[i, j]\n",
    "            ax.text(\n",
    "                j, i, f\"{val:.2f}\",\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if abs(val) > 0.6 else \"black\",\n",
    "                fontsize=8\n",
    "            )\n",
    "    return im\n",
    "\n",
    "\n",
    "def stacked_barh(ax, labels, data, category_labels, title, x_label):\n",
    "    y = np.arange(len(labels))\n",
    "    left = np.zeros(len(labels))\n",
    "    for i, category in enumerate(category_labels):\n",
    "        values = np.nan_to_num(np.array(data.get(category, np.zeros(len(labels))), dtype=float))\n",
    "        ax.barh(y, values, left=left, label=category, height=0.6)\n",
    "        left += values\n",
    "    ax.set_yticks(y)\n",
    "    ax.set_yticklabels(labels)\n",
    "    ax.invert_yaxis()\n",
    "    ax.grid(True, axis=\"x\", linestyle=\":\", linewidth=0.5)\n",
    "    ax.set_title(title, fontsize=11)\n",
    "    ax.set_xlabel(x_label, fontsize=10)\n",
    "    ax.tick_params(axis=\"y\", labelsize=8)\n",
    "    ax.tick_params(axis=\"x\", labelsize=8)\n",
    "    ax.legend(fontsize=8, frameon=False)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# YAML energy helpers (NEW)\n",
    "# -----------------------------\n",
    "def parse_yaml_energy(path):\n",
    "    \"\"\"Return dict: {'SRAM': {...}, 'JanS': {...}} with keys read_hit_pJ, write_hit_pJ, miss_pJ, p_leak_mW.\"\"\"\n",
    "    if yaml is None:\n",
    "        return None\n",
    "    if not (isinstance(path, str) and os.path.isfile(path)):\n",
    "        print(f\"[YAML] Not found: {path}. Skipping YAML energy attribution.\")\n",
    "        return None\n",
    "    with open(path, \"r\") as f:\n",
    "        y = yaml.safe_load(f)\n",
    "    try:\n",
    "        s = y[\"llc\"][\"sram\"][\"energy\"]\n",
    "        j = y[\"llc\"][\"jans\"][\"energy\"]\n",
    "        out = {\n",
    "            \"SRAM\": {\n",
    "                \"read_hit_pJ\": float(s.get(\"e_read_hit_pJ\", np.nan)),\n",
    "                \"write_hit_pJ\": float(s.get(\"e_write_hit_pJ\", np.nan)),\n",
    "                \"miss_pJ\": float(s.get(\"e_miss_pJ\", np.nan)),\n",
    "                \"p_leak_mW\": float(s.get(\"p_leak_mW\", np.nan)),\n",
    "            },\n",
    "            \"JanS\": {\n",
    "                \"read_hit_pJ\": float(j.get(\"e_read_hit_pJ\", np.nan)),\n",
    "                \"write_hit_pJ\": float(j.get(\"e_write_hit_pJ\", np.nan)),\n",
    "                \"miss_pJ\": float(j.get(\"e_miss_pJ\", np.nan)),\n",
    "                \"p_leak_mW\": float(j.get(\"p_leak_mW\", np.nan)),\n",
    "            },\n",
    "        }\n",
    "        print(\"[YAML] Parsed energy pJ and leak mW for SRAM & JanS.\")\n",
    "        return out\n",
    "    except Exception as e:\n",
    "        print(f\"[YAML] Parse error: {e}. Skipping YAML energy attribution.\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Main\n",
    "# -----------------------------\n",
    "def main():\n",
    "    out_dir = os.getcwd()\n",
    "\n",
    "    # Load data\n",
    "    sniper = parse_sniper(SNIPER_RESULTS_DIR)\n",
    "    dr = parse_dynamorio(DYNAMORIO_LOGS_DIR, TIMESTAMP_PREFIX)\n",
    "\n",
    "    # Save raw inputs\n",
    "    sniper.to_csv(os.path.join(out_dir, \"sniper_raw.csv\"), index=False)\n",
    "    if not dr.empty:\n",
    "        dr.to_csv(os.path.join(out_dir, \"dynamorio_raw.csv\"), index=False)\n",
    "\n",
    "    print(\"\\n--- Processing and Filtering Data ---\")\n",
    "    # Focus on benchmarks present in BOTH SRAM and JanS\n",
    "    sram = sniper[sniper[\"config\"] == \"SRAM\"].set_index(\"benchmark\")\n",
    "    jans = sniper[sniper[\"config\"] == \"JanS\"].set_index(\"benchmark\")\n",
    "    common = sram.index.intersection(jans.index)\n",
    "    if len(common) == 0:\n",
    "        raise RuntimeError(\"No common benchmarks between SRAM and JanS.\")\n",
    "\n",
    "    print(f\"Found {len(common)} common benchmarks between SRAM and JanS configs: {common.tolist()}\")\n",
    "\n",
    "    sram = sram.loc[common].copy()\n",
    "    jans = jans.loc[common].copy()\n",
    "\n",
    "    # Sort by SRAM execution time to keep labels readable\n",
    "    order = sram.sort_values(\"time_s\").index.tolist()\n",
    "    sram = sram.loc[order]\n",
    "    jans = jans.loc[order]\n",
    "    labels = order\n",
    "\n",
    "    print(\"Sorted benchmarks by SRAM execution time:\", labels)\n",
    "    print(\"\\n--- SRAM Data (head) ---\")\n",
    "    print(sram.head())\n",
    "    print(\"\\n--- JanS Data (head) ---\")\n",
    "    print(jans.head())\n",
    "    print(\"-\" * 20)\n",
    "\n",
    "    # ---------------- Sniper comparisons (compact 2x2) ----------------\n",
    "    plt.rcParams.update({\n",
    "        \"figure.figsize\": (11, 8),\n",
    "        \"axes.titlesize\": 11,\n",
    "        \"axes.labelsize\": 10,\n",
    "        \"xtick.labelsize\": 8,\n",
    "        \"ytick.labelsize\": 8,\n",
    "    })\n",
    "    fig, axs = plt.subplots(2, 2)\n",
    "\n",
    "    # 1) Execution time (s)\n",
    "    grouped_barh(\n",
    "        axs[0, 0], labels,\n",
    "        sram[\"time_s\"].values, jans[\"time_s\"].values,\n",
    "        \"SRAM\", \"JanS\",\n",
    "        \"Execution Time\", \"seconds\",\n",
    "    )\n",
    "\n",
    "    # 2) Total LLC energy (J)\n",
    "    grouped_barh(\n",
    "        axs[0, 1], labels,\n",
    "        sram[\"energy_exact_J\"].values, jans[\"energy_exact_J\"].values,\n",
    "        \"SRAM\", \"JanS\",\n",
    "        \"LLC Energy (total)\", \"Joules\",\n",
    "    )\n",
    "\n",
    "    # 3) Dynamic LLC energy (J)\n",
    "    grouped_barh(\n",
    "        axs[1, 0], labels,\n",
    "        sram[\"dyn_exact_J\"].values, jans[\"dyn_exact_J\"].values,\n",
    "        \"SRAM\", \"JanS\",\n",
    "        \"LLC Energy (dynamic only)\", \"Joules\",\n",
    "    )\n",
    "\n",
    "    # 4) Leakage LLC energy (J)\n",
    "    grouped_barh(\n",
    "        axs[1, 1], labels,\n",
    "        sram[\"leak_J\"].values, jans[\"leak_J\"].values,\n",
    "        \"SRAM\", \"JanS\",\n",
    "        \"LLC Energy (leakage only)\", \"Joules\",\n",
    "    )\n",
    "\n",
    "    fig.suptitle(\"SRAM vs JanS — Timing and Energy (per benchmark)\", fontsize=12, y=0.99)\n",
    "    fig.tight_layout(rect=[0, 0, 1, 0.97])\n",
    "\n",
    "    # ------------------ Figure: Normalized Performance Summary ------------------\n",
    "    norm = pd.DataFrame(index=order)\n",
    "    norm[\"norm_time\"] = safe_div(jans[\"time_s\"], sram[\"time_s\"])\n",
    "    norm[\"norm_energy\"] = safe_div(jans[\"energy_exact_J\"], sram[\"energy_exact_J\"])\n",
    "\n",
    "    print(\"\\n--- Normalized Data (JanS / SRAM) ---\")\n",
    "    print(norm)\n",
    "    print(\"-\" * 20)\n",
    "\n",
    "    fig2, axs2 = plt.subplots(2, 2, figsize=(11, 8))\n",
    "\n",
    "    # 1) Normalized Execution Time\n",
    "    axs2[0, 0].bar(norm.index, norm[\"norm_time\"])\n",
    "    axs2[0, 0].axhline(1.0, color='r', linestyle='--', linewidth=1.2)\n",
    "    axs2[0, 0].set_title(\"Normalized Execution Time (JanS / SRAM)\", fontsize=11)\n",
    "    axs2[0, 0].set_ylabel(\"Ratio (Lower is Better)\", fontsize=10)\n",
    "    axs2[0, 0].grid(True, axis=\"y\", linestyle=\":\")\n",
    "\n",
    "    # 2) Normalized Total LLC Energy\n",
    "    axs2[0, 1].bar(norm.index, norm[\"norm_energy\"])\n",
    "    axs2[0, 1].axhline(1.0, color='r', linestyle='--', linewidth=1.2)\n",
    "    axs2[0, 1].set_title(\"Normalized Total LLC Energy (JanS / SRAM)\", fontsize=11)\n",
    "    axs2[0, 1].set_ylabel(\"Ratio (Lower is Better)\", fontsize=10)\n",
    "    axs2[0, 1].grid(True, axis=\"y\", linestyle=\":\")\n",
    "\n",
    "    # 3) Absolute IPC\n",
    "    x = np.arange(len(labels))\n",
    "    width = 0.35\n",
    "    axs2[1, 0].bar(x - width/2, sram[\"ipc\"], width, label='SRAM')\n",
    "    axs2[1, 0].bar(x + width/2, jans[\"ipc\"], width, label='JanS')\n",
    "    axs2[1, 0].set_title(\"Instructions Per Cycle (IPC)\", fontsize=11)\n",
    "    axs2[1, 0].set_ylabel(\"IPC (Higher is Better)\", fontsize=10)\n",
    "    axs2[1, 0].legend(fontsize=8, frameon=False)\n",
    "\n",
    "    # 4) L3 Miss Rate (%)\n",
    "    if \"l3_miss_rate_pct\" in sram.columns and \"l3_miss_rate_pct\" in jans.columns:\n",
    "        axs2[1, 1].bar(x - width/2, sram[\"l3_miss_rate_pct\"], width, label='SRAM')\n",
    "        axs2[1, 1].bar(x + width/2, jans[\"l3_miss_rate_pct\"], width, label='JanS')\n",
    "        axs2[1, 1].set_title(\"L3 Miss Rate\", fontsize=11)\n",
    "        axs2[1, 1].set_ylabel(\"Miss Rate (%)\", fontsize=10)\n",
    "        axs2[1, 1].legend(fontsize=8, frameon=False)\n",
    "    else:\n",
    "        axs2[1, 1].axis(\"off\")\n",
    "\n",
    "    for ax in axs2.flatten():\n",
    "        ax.set_xticks(np.arange(len(labels)))\n",
    "        ax.set_xticklabels(labels, rotation=90)\n",
    "        ax.tick_params(axis=\"x\", labelsize=8)\n",
    "\n",
    "    # Geomeans for headline\n",
    "    gm_time = geomean(norm[\"norm_time\"]) if not np.all(np.isnan(norm[\"norm_time\"])) else np.nan\n",
    "    gm_energy = geomean(norm[\"norm_energy\"]) if not np.all(np.isnan(norm[\"norm_energy\"])) else np.nan\n",
    "    fig2.suptitle(\n",
    "        f\"Performance & Cache Metrics: SRAM vs. JanS — GeoMeans (JanS/SRAM): time={gm_time:.3f}, energy={gm_energy:.3f}\",\n",
    "        fontsize=13, y=0.99,\n",
    "    )\n",
    "    fig2.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "\n",
    "    # ------------------ Figure: LLC Energy Breakdown ------------------\n",
    "    fig_e, axs_e = plt.subplots(1, 2, figsize=(11, 5), sharex=True)\n",
    "    sram_energy_data = {'Dynamic': sram[\"dyn_exact_J\"], 'Leakage': sram[\"leak_J\"]}\n",
    "    jans_energy_data = {'Dynamic': jans[\"dyn_exact_J\"], 'Leakage': jans[\"leak_J\"]}\n",
    "\n",
    "    stacked_barh(axs_e[0], labels, sram_energy_data, ['Dynamic', 'Leakage'], \"SRAM LLC Energy Breakdown\", \"Joules\")\n",
    "    stacked_barh(axs_e[1], labels, jans_energy_data, ['Dynamic', 'Leakage'], \"JanS LLC Energy Breakdown\", \"Joules\")\n",
    "\n",
    "    fig_e.suptitle(\"LLC Energy Composition: Dynamic vs. Leakage\", fontsize=13, y=0.99)\n",
    "    fig_e.tight_layout(rect=[0, 0, 1, 0.94])\n",
    "\n",
    "    # ---------------- Mechanism View: pJ per ACCESS (preferred) + pJ per HIT (kept) ----------------\n",
    "    print(\"\\n--- Per-ACCESS / Per-HIT Dynamic Energy ---\")\n",
    "    sram_accesses = detect_total_accesses(sram)\n",
    "    jans_accesses = detect_total_accesses(jans)\n",
    "\n",
    "    sram_hits = detect_total_hits(sram)\n",
    "    jans_hits = detect_total_hits(jans)\n",
    "\n",
    "    # Per-ACCESS (preferred)\n",
    "    per_access_mode = sram_accesses is not None and jans_accesses is not None\n",
    "    if per_access_mode:\n",
    "        sram_pJ_access = safe_div(sram[\"dyn_exact_J\"] * 1e12, sram_accesses)\n",
    "        jans_pJ_access = safe_div(jans[\"dyn_exact_J\"] * 1e12, jans_accesses)\n",
    "        denom_label = \"LLC access\"\n",
    "\n",
    "        fig_pa, axs_pa = plt.subplots(1, 2, figsize=(11, 5))\n",
    "        grouped_barh(\n",
    "            axs_pa[0], labels,\n",
    "            sram_pJ_access, jans_pJ_access,\n",
    "            \"SRAM\", \"JanS\",\n",
    "            f\"Dynamic LLC Energy per {denom_label}\", f\"pJ / {denom_label}\"\n",
    "        )\n",
    "        ratio_pa = safe_div(jans_pJ_access, sram_pJ_access)\n",
    "        x = np.arange(len(labels))\n",
    "        axs_pa[1].bar(x, ratio_pa)\n",
    "        axs_pa[1].axhline(1.0, color='r', linestyle='--', linewidth=1.2)\n",
    "        axs_pa[1].set_title(f\"Normalized pJ/{denom_label} (JanS / SRAM)\")\n",
    "        axs_pa[1].set_ylabel(\"Ratio (Lower is Better)\")\n",
    "        axs_pa[1].set_xticks(x)\n",
    "        axs_pa[1].set_xticklabels(labels, rotation=90)\n",
    "        axs_pa[1].grid(True, axis=\"y\", linestyle=\":\")\n",
    "\n",
    "        gm_pa = geomean(ratio_pa)\n",
    "        fig_pa.suptitle(\n",
    "            f\"Mechanism: Dynamic Energy per {denom_label} — Geomean (JanS/SRAM) = {gm_pa:.3f}\",\n",
    "            fontsize=13, y=0.99,\n",
    "        )\n",
    "        fig_pa.tight_layout(rect=[0, 0, 1, 0.94])\n",
    "\n",
    "        pd.DataFrame({\n",
    "            \"benchmark\": labels,\n",
    "            \"SRAM_dyn_pJ_per_access\": sram_pJ_access,\n",
    "            \"JanS_dyn_pJ_per_access\": jans_pJ_access,\n",
    "            \"JanS_over_SRAM_pJ_per_access\": ratio_pa,\n",
    "            \"SRAM_accesses\": sram_accesses.reindex(labels).values,\n",
    "            \"JanS_accesses\": jans_accesses.reindex(labels).values,\n",
    "        }).set_index(\"benchmark\").to_csv(os.path.join(out_dir, \"per_access_dynamic_energy.csv\"))\n",
    "    else:\n",
    "        print(\"[per-access] Skipped: need total-access columns (e.g., l3_accesses_db) or fallbacks.\")\n",
    "\n",
    "    # Per-HIT (explicit)\n",
    "    per_hit_mode = sram_hits is not None and jans_hits is not None\n",
    "    if per_hit_mode:\n",
    "        sram_pJ_hit = safe_div(sram[\"dyn_exact_J\"] * 1e12, sram_hits)\n",
    "        jans_pJ_hit = safe_div(jans[\"dyn_exact_J\"] * 1e12, jans_hits)\n",
    "\n",
    "        fig_ph, axs_ph = plt.subplots(1, 2, figsize=(11, 5))\n",
    "        grouped_barh(\n",
    "            axs_ph[0], labels,\n",
    "            sram_pJ_hit, jans_pJ_hit,\n",
    "            \"SRAM\", \"JanS\",\n",
    "            \"Dynamic LLC Energy per HIT (read+write)\", \"pJ / hit\",\n",
    "        )\n",
    "        ratio_ph = safe_div(jans_pJ_hit, sram_pJ_hit)\n",
    "        x = np.arange(len(labels))\n",
    "        axs_ph[1].bar(x, ratio_ph)\n",
    "        axs_ph[1].axhline(1.0, color='r', linestyle='--', linewidth=1.2)\n",
    "        axs_ph[1].set_title(\"Normalized pJ/hit (JanS / SRAM)\")\n",
    "        axs_ph[1].set_ylabel(\"Ratio (Lower is Better)\")\n",
    "        axs_ph[1].set_xticks(x)\n",
    "        axs_ph[1].set_xticklabels(labels, rotation=90)\n",
    "        axs_ph[1].grid(True, axis=\"y\", linestyle=\":\")\n",
    "\n",
    "        gm_ph = geomean(ratio_ph)\n",
    "        fig_ph.suptitle(\n",
    "            f\"Mechanism: Dynamic Energy per HIT — Geomean (JanS/SRAM) = {gm_ph:.3f}\",\n",
    "            fontsize=13, y=0.99,\n",
    "        )\n",
    "        fig_ph.tight_layout(rect=[0, 0, 1, 0.94])\n",
    "\n",
    "        pd.DataFrame({\n",
    "            \"benchmark\": labels,\n",
    "            \"SRAM_dyn_pJ_per_hit\": sram_pJ_hit,\n",
    "            \"JanS_dyn_pJ_per_hit\": jans_pJ_hit,\n",
    "            \"JanS_over_SRAM_pJ_per_hit\": ratio_ph,\n",
    "            \"SRAM_hits\": sram_hits.reindex(labels).values,\n",
    "            \"JanS_hits\": jans_hits.reindex(labels).values,\n",
    "        }).set_index(\"benchmark\").to_csv(os.path.join(out_dir, \"per_hit_dynamic_energy.csv\"))\n",
    "    else:\n",
    "        print(\"[per-hit] Skipped: could not find read_hit + write_hit columns.\")\n",
    "\n",
    "    # ---------------- System-Level Analysis (Power & EDP) ----------------\n",
    "    print(\"\\n--- System-Level Analysis (Power & EDP) ---\")\n",
    "    sys = pd.DataFrame({\n",
    "        \"benchmark\": labels,\n",
    "        \"SRAM_time_s\": sram[\"time_s\"].values,\n",
    "        \"JanS_time_s\": jans[\"time_s\"].values,\n",
    "        \"SRAM_energy_J\": sram[\"energy_exact_J\"].values,\n",
    "        \"JanS_energy_J\": jans[\"energy_exact_J\"].values,\n",
    "        \"SRAM_dyn_W\": safe_div(sram[\"dyn_exact_J\"].values, sram[\"time_s\"].values),\n",
    "        \"JanS_dyn_W\": safe_div(jans[\"dyn_exact_J\"].values, jans[\"time_s\"].values),\n",
    "        \"SRAM_leak_W\": safe_div(sram[\"leak_J\"].values, sram[\"time_s\"].values),\n",
    "        \"JanS_leak_W\": safe_div(jans[\"leak_J\"].values, jans[\"time_s\"].values),\n",
    "    }).set_index(\"benchmark\")\n",
    "    sys[\"SRAM_EDP\"] = sys[\"SRAM_energy_J\"] * sys[\"SRAM_time_s\"]\n",
    "    sys[\"JanS_EDP\"] = sys[\"JanS_energy_J\"] * sys[\"JanS_time_s\"]\n",
    "    sys[\"SRAM_ED2P\"] = sys[\"SRAM_energy_J\"] * (sys[\"SRAM_time_s\"] ** 2)\n",
    "    sys[\"JanS_ED2P\"] = sys[\"JanS_energy_J\"] * (sys[\"JanS_time_s\"] ** 2)\n",
    "\n",
    "    sys[\"norm_EDP\"] = safe_div(sys[\"JanS_EDP\"].values, sys[\"SRAM_EDP\"].values)\n",
    "    sys[\"norm_ED2P\"] = safe_div(sys[\"JanS_ED2P\"].values, sys[\"SRAM_ED2P\"].values)\n",
    "\n",
    "    print(\"System-level metrics (head):\")\n",
    "    print(sys.head())\n",
    "    print(\"-\" * 20)\n",
    "\n",
    "    fig_sys, axs_sys = plt.subplots(1, 3, figsize=(14, 5))\n",
    "    grouped_barh(\n",
    "        axs_sys[0], labels,\n",
    "        sys[\"SRAM_dyn_W\"].values, sys[\"JanS_dyn_W\"].values,\n",
    "        \"SRAM\", \"JanS\", \"Dynamic Power (LLC)\", \"Watts\",\n",
    "    )\n",
    "    grouped_barh(\n",
    "        axs_sys[1], labels,\n",
    "        sys[\"SRAM_leak_W\"].values, sys[\"JanS_leak_W\"].values,\n",
    "        \"SRAM\", \"JanS\", \"Leakage Power (LLC)\", \"Watts\",\n",
    "    )\n",
    "\n",
    "    x = np.arange(len(labels))\n",
    "    axs_sys[2].bar(x, sys[\"norm_EDP\"].values)\n",
    "    axs_sys[2].axhline(1.0, linestyle=\"--\", linewidth=1.2, color=\"r\")\n",
    "    axs_sys[2].set_xticks(x)\n",
    "    axs_sys[2].set_xticklabels(labels, rotation=90)\n",
    "    axs_sys[2].set_ylabel(\"Ratio (Lower is Better)\")\n",
    "    axs_sys[2].set_title(\"EDP (JanS / SRAM)\")\n",
    "    fig_sys.suptitle(\"System Power & EDP\", fontsize=13, y=0.99)\n",
    "    fig_sys.tight_layout(rect=[0, 0, 1, 0.94])\n",
    "\n",
    "    # ---------------- Correlation: DynamoRIO features vs totals / gains ----------------\n",
    "    \n",
    "    if not dr.empty:\n",
    "        print(\"\\n--- Building Correlation Matrix Data (Spearman + Pearson) ---\")\n",
    "        feat_map = {\n",
    "            \"rtotal\": \"read_total\",\n",
    "            \"runique\": \"read_unique\",\n",
    "            \"90%f_tr\": \"read_footprint90L\",\n",
    "            \"Hrg\": \"read_entropy\",\n",
    "            \"Hrl\": \"read_local_entropy\",\n",
    "            \"wtotal\": \"write_total\",\n",
    "            \"wunique\": \"write_unique\",\n",
    "            \"90%f_tw\": \"write_footprint90L\",\n",
    "            \"Hwg\": \"write_entropy\",\n",
    "            \"Hwl\": \"write_local_entropy\",\n",
    "        }\n",
    "\n",
    "        feats = pd.DataFrame({\"benchmark\": dr[\"benchmark\"]})\n",
    "        for out_name, src in feat_map.items():\n",
    "            feats[out_name] = pd.to_numeric(dr.get(src), errors=\"coerce\")\n",
    "        feats = feats.set_index(\"benchmark\")\n",
    "\n",
    "        # Additional DR-derived features (ratios, intensities)\n",
    "        print(\"Calculating additional DynamoRIO features (ratios, intensities)...\")\n",
    "        dr_idx = dr.set_index(\"benchmark\")\n",
    "        instr_col_name = 'instrs' if 'instrs' in dr_idx.columns else ('instructions' if 'instructions' in dr_idx.columns else None)\n",
    "\n",
    "        if instr_col_name:\n",
    "            instr_count = pd.to_numeric(dr_idx[instr_col_name], errors='coerce')\n",
    "            feats['read_intensity'] = safe_div(feats['rtotal'], instr_count)\n",
    "            feats['write_intensity'] = safe_div(feats['wtotal'], instr_count)\n",
    "        else:\n",
    "            print(\"Warning: total instruction column not found in DR logs. Skipping intensity features.\")\n",
    "\n",
    "        feats['rw_ratio_total'] = safe_div(feats['rtotal'], feats['wtotal'])\n",
    "        feats['rw_ratio_unique'] = safe_div(feats['runique'], feats['wunique'])\n",
    "        feats['rw_ratio_global_entropy'] = safe_div(feats['Hrg'], feats['Hwg'])\n",
    "        feats['rw_ratio_local_entropy'] = safe_div(feats['Hrl'], feats['Hwl'])\n",
    "        feats['rw_ratio_90_footprint'] = safe_div(feats['90%f_tr'], feats['90%f_tw'])\n",
    "\n",
    "        # MODIFICATION: Targets are now JanS absolute metrics\n",
    "        targets_jans = jans[[\"time_s\", \"energy_exact_J\", \"dyn_exact_J\", \"ipc\"]].copy()\n",
    "        if \"l3_miss_rate_pct\" in jans.columns:\n",
    "            targets_jans[\"L3_miss%\"] = jans[\"l3_miss_rate_pct\"]\n",
    "        targets_jans = targets_jans.rename(columns={\n",
    "            \"time_s\": \"exe_time\", \"energy_exact_J\": \"LLC_energy\", \"dyn_exact_J\": \"Dyn_energy\", \"ipc\": \"IPC\",\n",
    "        })\n",
    "\n",
    "        corr_df = feats.join(targets_jans, how=\"inner\").join(norm, how=\"inner\").join(sys, how=\"inner\")\n",
    "\n",
    "        # Per-access / per-hit extras\n",
    "        extra_cols = []\n",
    "        if per_access_mode:\n",
    "            # Note: SRAM is still the baseline for the \"absolute\" pJ/access metric here\n",
    "            corr_df[\"pJ/access (SRAM)\"] = pd.Series(sram_pJ_access, index=labels)\n",
    "            corr_df[\"norm_pJ/access (JanS/SRAM)\"] = pd.Series(ratio_pa, index=labels)\n",
    "            extra_cols += [\"pJ/access (SRAM)\", \"norm_pJ/access (JanS/SRAM)\"]\n",
    "        if per_hit_mode:\n",
    "            corr_df[\"pJ/hit (SRAM)\"] = pd.Series(sram_pJ_hit, index=labels)\n",
    "            corr_df[\"norm_pJ/hit (JanS/SRAM)\"] = pd.Series(ratio_ph, index=labels)\n",
    "            extra_cols += [\"pJ/hit (SRAM)\", \"norm_pJ/hit (JanS/SRAM)\"]\n",
    "\n",
    "        print(\"Correlation DataFrame (head):\")\n",
    "        print(corr_df.head())\n",
    "        print(\"-\" * 20)\n",
    "\n",
    "        base_feature_names = list(feat_map.keys())\n",
    "        new_feature_names = ['read_intensity','write_intensity','rw_ratio_total','rw_ratio_unique',\n",
    "                             'rw_ratio_global_entropy','rw_ratio_local_entropy','rw_ratio_90_footprint']\n",
    "        feature_names = [c for c in base_feature_names + new_feature_names\n",
    "                         if c in corr_df.columns and not corr_df[c].isna().all()]\n",
    "\n",
    "        # MODIFICATION: Use JanS EDP and ED2P columns\n",
    "        abs_cols = [c for c in [\"exe_time\", \"LLC_energy\", \"Dyn_energy\", \"IPC\", \"L3_miss%\", \"JanS_EDP\", \"JanS_ED2P\"]\n",
    "                    if c in corr_df.columns and not corr_df[c].isna().all()]\n",
    "\n",
    "        norm_cols = [c for c in [\"norm_time\",\"norm_energy\",\"norm_EDP\",\"norm_ED2P\"]\n",
    "                     if c in corr_df.columns and not corr_df[c].isna().all()]\n",
    "        cols2 = norm_cols + extra_cols\n",
    "\n",
    "        if feature_names and (abs_cols or cols2) and len(corr_df.dropna(how=\"all\")) >= 2:\n",
    "            for method, pretty in [(\"spearman\", \"Spearman’s \\u03c1\"), (\"pearson\", \"Pearson’s r\")]:\n",
    "                fig_c, axs_c = plt.subplots(1, 2, figsize=(11, 7))\n",
    "\n",
    "                # Features vs. JanS absolute metrics\n",
    "                if abs_cols:\n",
    "                    C1 = corr_df[feature_names + abs_cols].corr(method=method).loc[feature_names, abs_cols].values\n",
    "                    # MODIFICATION: Updated title to reflect JanS\n",
    "                    corr_heatmap(axs_c[0], C1, feature_names, abs_cols, f\"Features vs. JanS Totals & EDP ({pretty})\")\n",
    "                else:\n",
    "                    axs_c[0].axis(\"off\")\n",
    "\n",
    "                # Features vs. normalized gains (+ per-access/per-hit)\n",
    "                if cols2:\n",
    "                    C2 = corr_df[feature_names + cols2].corr(method=method).loc[feature_names, cols2].values\n",
    "                    corr_heatmap(axs_c[1], C2, feature_names, cols2, f\"Features vs. Gains ({pretty})\")\n",
    "                else:\n",
    "                    axs_c[1].axis(\"off\")\n",
    "\n",
    "                fig_c.suptitle(f\"Correlation: Memory Features \\u2194 Performance — {pretty}\", fontsize=13, y=0.99)\n",
    "                fig_c.tight_layout(rect=[0, 0, 1, 0.94])\n",
    "        else:\n",
    "            print(\"Not enough data for correlation heatmaps (missing features/targets or too few benchmarks).\")\n",
    "    else:\n",
    "        print(\"DynamoRIO features unavailable — skipping correlation plots.\")\n",
    "    \n",
    "    \n",
    "    # ---------------- Per-MISS dynamic energy (prefer actual misses) ----------------\n",
    "    sram_misses = detect_misses(sram)\n",
    "    jans_misses = detect_misses(jans)\n",
    "\n",
    "    if sram_misses is not None and jans_misses is not None:\n",
    "        print(\"\\n--- Per-Miss Dynamic Energy (actual) ---\")\n",
    "        x = np.arange(len(labels))\n",
    "        pJmiss_s = safe_div(sram[\"dyn_exact_J\"].values * 1e12, sram_misses.reindex(labels).values)\n",
    "        pJmiss_j = safe_div(jans[\"dyn_exact_J\"].values * 1e12, jans_misses.reindex(labels).values)\n",
    "        r_pm = safe_div(pJmiss_j, pJmiss_s)\n",
    "\n",
    "        pm_df = pd.DataFrame({\n",
    "            'sram_misses': sram_misses.reindex(labels).values,\n",
    "            'jans_misses': jans_misses.reindex(labels).values,\n",
    "            'sram_pJ_per_miss': pJmiss_s,\n",
    "            'jans_pJ_per_miss': pJmiss_j,\n",
    "            'ratio_pJ_per_miss': r_pm,\n",
    "        }, index=labels)\n",
    "        print(\"Per-miss energy data (head):\")\n",
    "        print(pm_df.head())\n",
    "        print(\"-\" * 20)\n",
    "\n",
    "        fig_pm, axs_pm = plt.subplots(1, 2, figsize=(11, 5))\n",
    "        grouped_barh(axs_pm[0], labels, pJmiss_s, pJmiss_j,\n",
    "                     \"SRAM\", \"JanS\", \"Dynamic Energy per L3 Miss\", \"pJ / miss\")\n",
    "\n",
    "        axs_pm[1].bar(x, r_pm)\n",
    "        axs_pm[1].axhline(1.0, linestyle=\"--\", linewidth=1.2, color=\"r\")\n",
    "        axs_pm[1].set_xticks(x)\n",
    "        axs_pm[1].set_xticklabels(labels, rotation=90)\n",
    "        axs_pm[1].set_ylabel(\"Ratio (Lower is Better)\")\n",
    "        axs_pm[1].set_title(\"pJ/miss (JanS / SRAM)\")\n",
    "        fig_pm.suptitle(\"Per-Miss Dynamic Energy (actual)\", y=0.99)\n",
    "        fig_pm.tight_layout(rect=[0, 0, 1, 0.94])\n",
    "\n",
    "        pm_df.to_csv(os.path.join(out_dir, \"per_miss_dynamic_energy.csv\"))\n",
    "    else:\n",
    "        print(\"[per-miss] Skipped: no miss columns available.\")\n",
    "\n",
    "    # ---------------- Event-cost fit (NEW: fit using three columns: read_hit, write_hit, miss) ----------------\n",
    "    def _find_three_event_cols(df_config):\n",
    "        mapping = {\n",
    "            \"read_hit\": _choose_col(df_config, [\"read\", \"hit\"]),\n",
    "            \"write_hit\": _choose_col(df_config, [\"write\", \"hit\"]),\n",
    "            # prefer explicit *_misses_db\n",
    "            \"miss\": (\n",
    "                \"l3_misses_db\" if \"l3_misses_db\" in df_config.columns else (\n",
    "                    \"llc_misses_db\" if \"llc_misses_db\" in df_config.columns else _choose_col(df_config, [\"miss\"]) )\n",
    "            ),\n",
    "        }\n",
    "        return {k: v for k, v in mapping.items() if v}\n",
    "\n",
    "    def _fit_three_costs(df_config, cols3):\n",
    "        if not cols3 or \"dyn_exact_J\" not in df_config.columns:\n",
    "            return None, None\n",
    "        X_cols = list(cols3.values())\n",
    "        X = np.column_stack([pd.to_numeric(df_config[c], errors=\"coerce\").fillna(0.0).values for c in X_cols])\n",
    "        y = pd.to_numeric(df_config[\"dyn_exact_J\"], errors=\"coerce\").values\n",
    "        mask = np.isfinite(y)\n",
    "        for i in range(X.shape[1]):\n",
    "            mask &= np.isfinite(X[:, i])\n",
    "        X, y = X[mask], y[mask]\n",
    "        if X.shape[0] < len(X_cols):\n",
    "            return None, None\n",
    "        beta, *_ = np.linalg.lstsq(np.column_stack([np.ones(X.shape[0]), X]), y, rcond=None)\n",
    "        # beta[0] is intercept (J), beta[1:] are J/event for [read_hit, write_hit, miss]\n",
    "        coefs_pJ = beta[1:] * 1e12\n",
    "        y_hat = np.column_stack([np.ones(X.shape[0]), X]) @ beta\n",
    "        r2 = 1.0 - ((y - y_hat) ** 2).sum() / max(1e-12, ((y - y.mean()) ** 2).sum())\n",
    "        return pd.Series(coefs_pJ, index=list(cols3.keys())), r2\n",
    "\n",
    "    s_cols = _find_three_event_cols(sram)\n",
    "    j_cols = _find_three_event_cols(jans)\n",
    "    coef_s, r2_s = _fit_three_costs(sram, s_cols)\n",
    "    coef_j, r2_j = _fit_three_costs(jans, j_cols)\n",
    "\n",
    "    if coef_s is not None or coef_j is not None:\n",
    "        print(\"\\n--- Fitted Event Costs (3-term: read_hit, write_hit, miss) ---\")\n",
    "        print(f\"SRAM event columns used: {s_cols}\")\n",
    "        print(f\"JanS event columns used: {j_cols}\")\n",
    "\n",
    "        keys = [\"read_hit\", \"write_hit\", \"miss\"]\n",
    "        s_vals = np.array([coef_s.get(k, np.nan) if coef_s is not None else np.nan for k in keys])\n",
    "        j_vals = np.array([coef_j.get(k, np.nan) if coef_j is not None else np.nan for k in keys])\n",
    "\n",
    "        fit_df = pd.DataFrame({\n",
    "            'event_type': keys,\n",
    "            'SRAM_pJ_per_event': s_vals,\n",
    "            'JanS_pJ_per_event': j_vals,\n",
    "        }).set_index('event_type')\n",
    "        print(\"Fitted coefficients (pJ/event):\")\n",
    "        print(fit_df)\n",
    "        print(f\"SRAM R² = {r2_s if r2_s is not None else float('nan'):.3f}, JanS R² = {r2_j if r2_j is not None else float('nan'):.3f}\")\n",
    "        print(\"-\" * 20)\n",
    "\n",
    "        fig_ev, ax_ev = plt.subplots(1, 1, figsize=(10, 4.8))\n",
    "        xx = np.arange(len(keys)); w = 0.42\n",
    "        ax_ev.bar(xx - w/2, s_vals, width=w, label=\"SRAM\")\n",
    "        ax_ev.bar(xx + w/2, j_vals, width=w, label=\"JanS\")\n",
    "        ax_ev.set_xticks(xx)\n",
    "        ax_ev.set_xticklabels(keys)\n",
    "        ax_ev.set_ylabel(\"pJ / event\")\n",
    "        ax_ev.set_title(\"Fitted LLC Event Costs (3-term)\")\n",
    "        ax_ev.grid(True, axis=\"y\", linestyle=\":\")\n",
    "        ax_ev.legend(fontsize=8, frameon=False)\n",
    "        fig_ev.suptitle(\n",
    "            f\"Event-Cost Fit — R² SRAM={r2_s if r2_s is not None else float('nan'):.2f}, JanS={r2_j if r2_j is not None else float('nan'):.2f}\",\n",
    "            y=0.99,\n",
    "        )\n",
    "        fig_ev.tight_layout(rect=[0, 0, 1, 0.94])\n",
    "\n",
    "        fit_df.to_csv(os.path.join(out_dir, \"event_cost_fit_3term.csv\"))\n",
    "    else:\n",
    "        print(\"[event-fit] Skipped: insufficient hit/miss columns for 3-term fit.\")\n",
    "\n",
    "    # ---------------- YAML-based dynamic energy attribution (reads / writes / misses) ----------------\n",
    "    yaml_energy = parse_yaml_energy(YAML_CONFIG_PATH)\n",
    "    if yaml_energy is not None:\n",
    "        rh_col_s = _choose_col(sram, [\"read\", \"hit\"])  # best read-hit\n",
    "        wh_col_s = _choose_col(sram, [\"write\", \"hit\"]) # best write-hit\n",
    "        ms_col_s = \"l3_misses_db\" if \"l3_misses_db\" in sram.columns else (\n",
    "            \"llc_misses_db\" if \"llc_misses_db\" in sram.columns else _choose_col(sram, [\"miss\"]))\n",
    "\n",
    "        rh_col_j = _choose_col(jans, [\"read\", \"hit\"])  # best read-hit\n",
    "        wh_col_j = _choose_col(jans, [\"write\", \"hit\"]) # best write-hit\n",
    "        ms_col_j = \"l3_misses_db\" if \"l3_misses_db\" in jans.columns else (\n",
    "            \"llc_misses_db\" if \"llc_misses_db\" in jans.columns else _choose_col(jans, [\"miss\"]))\n",
    "\n",
    "        def _attrib(df_config, energy_dict, rh_col, wh_col, ms_col):\n",
    "            if rh_col is None and wh_col is None and ms_col is None:\n",
    "                return None\n",
    "            RH = pd.to_numeric(df_config[rh_col], errors='coerce') if rh_col else pd.Series(0.0, index=df_config.index)\n",
    "            WH = pd.to_numeric(df_config[wh_col], errors='coerce') if wh_col else pd.Series(0.0, index=df_config.index)\n",
    "            MS = pd.to_numeric(df_config[ms_col], errors='coerce') if ms_col else pd.Series(0.0, index=df_config.index)\n",
    "\n",
    "            eRH = energy_dict.get(\"read_hit_pJ\", np.nan) * 1e-12\n",
    "            eWH = energy_dict.get(\"write_hit_pJ\", np.nan) * 1e-12\n",
    "            eMS = energy_dict.get(\"miss_pJ\", np.nan) * 1e-12\n",
    "\n",
    "            comp = pd.DataFrame({\n",
    "                'Read hits (J)': RH * eRH,\n",
    "                'Write hits (J)': WH * eWH,\n",
    "                'Misses (J)': MS * eMS,\n",
    "            }, index=df_config.index)\n",
    "            comp['Total (J)'] = comp.sum(axis=1)\n",
    "            return comp\n",
    "\n",
    "        comp_s = _attrib(sram, yaml_energy[\"SRAM\"], rh_col_s, wh_col_s, ms_col_s)\n",
    "        comp_j = _attrib(jans, yaml_energy[\"JanS\"], rh_col_j, wh_col_j, ms_col_j)\n",
    "\n",
    "        if comp_s is not None and comp_j is not None:\n",
    "            print(\"\\n--- YAML-based Dynamic Energy Attribution (J) ---\")\n",
    "            print(\"SRAM (head):\\n\", comp_s.head())\n",
    "            print(\"JanS (head):\\n\", comp_j.head())\n",
    "\n",
    "            # Save CSVs\n",
    "            comp_s.loc[labels].to_csv(os.path.join(out_dir, \"yaml_dyn_breakdown_sram.csv\"))\n",
    "            comp_j.loc[labels].to_csv(os.path.join(out_dir, \"yaml_dyn_breakdown_jans.csv\"))\n",
    "\n",
    "            # Plot stacks\n",
    "            fig_y, axs_y = plt.subplots(1, 2, figsize=(12, 6), sharey=True)\n",
    "            stacked_barh(\n",
    "                axs_y[0], labels,\n",
    "                {\n",
    "                    'Read hits (J)': comp_s.loc[labels]['Read hits (J)'].values,\n",
    "                    'Write hits (J)': comp_s.loc[labels]['Write hits (J)'].values,\n",
    "                    'Misses (J)': comp_s.loc[labels]['Misses (J)'].values,\n",
    "                },\n",
    "                ['Read hits (J)', 'Write hits (J)', 'Misses (J)'],\n",
    "                \"SRAM Dynamic Energy Attribution (YAML pJ × counters)\",\n",
    "                \"Joules\",\n",
    "            )\n",
    "            stacked_barh(\n",
    "                axs_y[1], labels,\n",
    "                {\n",
    "                    'Read hits (J)': comp_j.loc[labels]['Read hits (J)'].values,\n",
    "                    'Write hits (J)': comp_j.loc[labels]['Write hits (J)'].values,\n",
    "                    'Misses (J)': comp_j.loc[labels]['Misses (J)'].values,\n",
    "                },\n",
    "                ['Read hits (J)', 'Write hits (J)', 'Misses (J)'],\n",
    "                \"JanS Dynamic Energy Attribution (YAML pJ × counters)\",\n",
    "                \"Joules\",\n",
    "            )\n",
    "            fig_y.suptitle(\"Dynamic Energy by Type (reads / writes / misses) via YAML\", fontsize=13, y=0.99)\n",
    "            fig_y.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "\n",
    "            # Compare to measured dyn_exact_J\n",
    "            cmp = pd.DataFrame({\n",
    "                'SRAM_measured_dyn_J': sram['dyn_exact_J'].loc[labels].values,\n",
    "                'SRAM_yaml_sum_J': comp_s.loc[labels]['Total (J)'].values,\n",
    "                'JanS_measured_dyn_J': jans['dyn_exact_J'].loc[labels].values,\n",
    "                'JanS_yaml_sum_J': comp_j.loc[labels]['Total (J)'].values,\n",
    "            }, index=labels)\n",
    "            cmp.to_csv(os.path.join(out_dir, \"yaml_vs_measured_dyn.csv\"))\n",
    "            print(\"YAML vs measured dynamic energy (head):\\n\", cmp.head())\n",
    "        else:\n",
    "            print(\"[YAML] Skipped attribution: missing hit/miss columns or YAML values.\")\n",
    "    else:\n",
    "        print(\"[YAML] Skipped: config not provided or PyYAML missing.\")\n",
    "\n",
    "    # -------- Save headline geomeans --------\n",
    "    geomean_df = pd.DataFrame({\n",
    "        \"metric\": [\"time (JanS/SRAM)\", \"total LLC energy (JanS/SRAM)\"],\n",
    "        \"geomean_ratio\": [gm_time, gm_energy],\n",
    "    })\n",
    "    print(\"\\n--- Geomean Summary ---\")\n",
    "    print(geomean_df)\n",
    "    print(\"-\" * 20)\n",
    "    geomean_df.to_csv(os.path.join(out_dir, \"geomean_summary.csv\"), index=False)\n",
    "\n",
    "    print(\"\\n--- Displaying all generated plots ---\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d19a89-880b-4cd1-b40e-1945da81d3e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
